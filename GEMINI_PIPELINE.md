# Pipeline de Extra√ß√£o de PDFs com Google Gemini

Este documento explica como funciona o sistema de download e extra√ß√£o de texto de PDFs usando o Google Gemini.

## üèóÔ∏è Arquitetura

O sistema usa 3 pipelines em sequ√™ncia:

1. **ProposicaoFilesPipeline**: Baixa arquivos PDF das proposi√ß√µes
2. **GeminiPDFExtractionPipeline**: Extrai texto dos PDFs usando Gemini
3. **ValidationPipeline**: Valida dados antes de salvar
4. **JsonWriterSinglePipeline**: Salva tudo em JSON

## üìã Configura√ß√£o

### 1. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 2. Configurar API do Gemini

Adicione sua chave da API do Gemini no arquivo `.env`:

```env
GEMINI_API_KEY="sua-chave-aqui"
```

Para obter uma chave gratuita:
1. Acesse https://aistudio.google.com/app/apikey
2. Crie uma nova API key
3. Copie e cole no arquivo `.env`

### 3. Estrutura de Pastas

Os arquivos ser√£o salvos em:
```
downloads/
  ‚îî‚îÄ‚îÄ proposicoespcd/
      ‚îî‚îÄ‚îÄ 2025/
          ‚îú‚îÄ‚îÄ 123_2025_abc123.pdf
          ‚îú‚îÄ‚îÄ 124_2025_def456.pdf
          ‚îî‚îÄ‚îÄ ...
```

## üï∑Ô∏è Como Usar nos Spiders

### Exemplo B√°sico

```python
import scrapy
from assessorai_crawler.items import ProposicaoItem

class MeuSpider(scrapy.Spider):
    name = "meuspider"
    
    def parse_detail(self, response):
        item = ProposicaoItem()
        
        # Preencher campos b√°sicos
        item['title'] = response.css('h1::text').get()
        item['house'] = 'Casa Legislativa'
        item['url'] = response.url
        # ... outros campos ...
        
        # Coletar URLs de PDFs
        file_urls = []
        for link in response.css('a[href$=".pdf"]'):
            pdf_url = response.urljoin(link.attrib['href'])
            file_urls.append(pdf_url)
        
        item['file_urls'] = file_urls  # O pipeline far√° o resto!
        
        yield item
```

### O que Acontece Automaticamente

1. **Download**: `ProposicaoFilesPipeline` baixa todos os PDFs listados em `file_urls`
2. **Extra√ß√£o**: `GeminiPDFExtractionPipeline` processa cada PDF com Gemini
3. **Preenchimento**: O campo `full_text` √© automaticamente preenchido com o texto extra√≠do
4. **Salvamento**: Tudo √© salvo em JSON

## üéØ Prompt de Extra√ß√£o

O pipeline usa um prompt especializado para documentos legislativos:

```
Voc√™ √© um assistente especializado em extrair texto de documentos legislativos brasileiros.

Extraia o texto completo deste documento PDF, preservando:
- A estrutura de artigos, par√°grafos e incisos
- Numera√ß√£o e formata√ß√£o legal
- Texto de justificativas e ementas

Retorne apenas o texto extra√≠do em formato markdown, sem coment√°rios adicionais.
Organize o texto de forma clara e estruturada.
```

### Customizar o Prompt

Edite o arquivo `pipelines.py`, na classe `GeminiPDFExtractionPipeline`:

```python
self.extraction_prompt = """
Seu prompt customizado aqui...
"""
```

## üîß Configura√ß√µes Avan√ßadas

### Desabilitar Extra√ß√£o de PDF

Se quiser apenas baixar os PDFs sem extrair texto:

```python
# settings.py
ITEM_PIPELINES = {
    "assessorai_crawler.pipelines.ProposicaoFilesPipeline": 1,
    # Comentar a linha abaixo para desabilitar extra√ß√£o
    # "assessorai_crawler.pipelines.GeminiPDFExtractionPipeline": 2,
    "assessorai_crawler.pipelines.ValidationPipeline": 100,
    "assessorai_crawler.pipelines.JsonWriterSinglePipeline": 300,
}
```

### Mudar Local de Download

```python
# settings.py
FILES_STORE = 'minha_pasta_personalizada'
```

### Ajustar Tempo de Expira√ß√£o

```python
# settings.py
FILES_EXPIRES = 90  # Dias (0 = nunca expira)
```

## üìä Campos do ProposicaoItem

### Campos Obrigat√≥rios

- `title`: T√≠tulo da proposi√ß√£o
- `house`: Casa legislativa
- `subject`: Ementa/assunto
- `url`: URL p√∫blica da proposi√ß√£o
- `full_text`: Texto completo (preenchido automaticamente)

### Campos para Download de Arquivos

- `file_urls`: Lista de URLs de PDFs para baixar
- `files`: Lista de caminhos dos arquivos baixados (preenchido automaticamente)

### Exemplo Completo

```python
item = ProposicaoItem()
item['title'] = 'PL 123/2025'
item['house'] = 'C√¢mara Municipal'
item['type'] = 'PL'
item['number'] = 123
item['year'] = 2025
item['author'] = ['Vereador A', 'Vereador B']
item['subject'] = 'Disp√µe sobre...'
item['url'] = 'https://site.gov.br/pl/123'
item['uuid'] = hashlib.md5(item['title'].encode()).hexdigest()
item['scraped_at'] = datetime.now().isoformat()

# URLs dos PDFs
item['file_urls'] = [
    'https://site.gov.br/pdf/123.pdf',
    'https://site.gov.br/pdf/123-emenda.pdf'
]

# Estes campos s√£o preenchidos automaticamente:
# item['files'] = [...]  # Pelo ProposicaoFilesPipeline
# item['full_text'] = '...'  # Pelo GeminiPDFExtractionPipeline
# item['length'] = 12345  # Pelo GeminiPDFExtractionPipeline

yield item
```

## üöÄ Exemplo Pr√°tico: Po√ßos de Caldas

```bash
# Executar spider de Po√ßos de Caldas para 2025
scrapy crawl proposicoespcd -a ano=2025

# O spider ir√°:
# 1. Acessar p√°gina de listagem
# 2. Para cada proposi√ß√£o, entrar na p√°gina de detalhes
# 3. Coletar URLs de todos os PDFs
# 4. Baixar PDFs automaticamente
# 5. Extrair texto com Gemini
# 6. Salvar JSON com texto completo
```

## ‚ö†Ô∏è Considera√ß√µes

### Custos da API

O Gemini possui um tier gratuito generoso, mas fique atento:
- **Gemini 1.5 Flash**: 15 requisi√ß√µes/minuto (gratuito)
- **Limite di√°rio**: Verifique em https://aistudio.google.com/app/apikey

### Tratamento de Erros

O pipeline loga erros e continua:
```python
# Se um PDF falhar, os outros continuam sendo processados
# Erros s√£o logados mas n√£o interrompem a execu√ß√£o
```

### Performance

- PDFs grandes podem levar alguns segundos
- O Gemini processa em batch quando poss√≠vel
- Arquivos s√£o cacheados localmente

## üêõ Debug

### Ver logs detalhados

```bash
scrapy crawl proposicoespcd -a ano=2025 -L DEBUG
```

### Testar apenas 5 itens

```bash
scrapy crawl proposicoespcd -a ano=2025 -s CLOSESPIDER_ITEMCOUNT=5
```

### Verificar arquivos baixados

```bash
ls -la downloads/proposicoespcd/2025/
```

## üìö Recursos

- [Documenta√ß√£o do Scrapy FilesPipeline](https://docs.scrapy.org/en/latest/topics/media-pipeline.html)
- [Documenta√ß√£o do Google Gemini](https://ai.google.dev/docs)
- [Gemini API Pricing](https://ai.google.dev/pricing)
